@code_type ruby .
@comment_type # %s
@include doc/layout.lit
@title Computer-aided Day Trading

@s Computer-aided Day Trading

The stock market generally overreacts. When good news is published, the price
rises before subsequently falling some amount. When bad news is published, the
price plummets before subsequently rising some amount. One method of automation
would be scanning the news for headlines, measuring the sentiment, and then
investing when the price drops -- the news tells you where to look. Another
option is to scan the entire market and look for drops that likely result from
such news.

My method is to do exactly that: scan the entire market for a precipitous drop
in price over two days (opening of the first to closing of the second), and then
invest. How can I take advantage of that? How do I know when to sell? When
should I be satisfied with a stock's performance?

The database is discussed [here](/files/db.html).

@s The Process

The process starts simply: we answer the questions of "when do we buy" and "when
do we sell".

A stock price will drop and then it will likely go back up, due to **mean
reversion**. We are measuring several different dimensions for the best outcome,
which make this a difficult (annoying?) problem to solve without the help of
more computing power. As an intermediate step, I've settled on the figures in
this document, which have lent themselves to the below results:

<center>
<table>
  <tr>
    <th>Year</th>
    <th># of Buys</th>
    <th># Unsold</th>
    <th># Delist.</th>
    <th>Med. Hold</th>
    <th>S&P 500</th>
    <th>Mean ROI</th>
    <th>Median</th>
    <th>STDDEV</th>
    <th>Sharpe</th>
  </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2021.html">2021</a>
      </td>
      <td>109</td>
      <td>75</td>
      <td>12</td>
      <td>(unsold)</td>
      <td>26.013%</td>
      <td>-38.655%</td>
      <td>-100%</td>
      <td>98.182%</td>
      <td>-0.394</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2020.html">2020</a>
      </td>
      <td>326</td>
      <td>24</td>
      <td>5</td>
      <td>85</td>
      <td>16.644%</td>
      <td>79.78%</td>
      <td>51.376%</td>
      <td>106.792%</td>
      <td>0.747</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2019.html">2019</a>
      </td>
      <td>56</td>
      <td>9</td>
      <td>6</td>
      <td>99</td>
      <td>28.971%</td>
      <td>40.3%</td>
      <td>18.254%</td>
      <td>102.768%</td>
      <td>0.392</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2018.html">2018</a>
      </td>
      <td>36</td>
      <td>9</td>
      <td>6</td>
      <td>120</td>
      <td>-6.691%</td>
      <td>2.038%</td>
      <td>3.093%</td>
      <td>79.494%</td>
      <td>0.026</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2017.html">2017</a>
      </td>
      <td>35</td>
      <td>8</td>
      <td>4</td>
      <td>119</td>
      <td>18.747%</td>
      <td>-9.838%</td>
      <td>2.154%</td>
      <td>52.169%</td>
      <td>-0.189</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2016.html">2016</a>
      </td>
      <td>44</td>
      <td>5</td>
      <td>4</td>
      <td>82</td>
      <td>8.97%</td>
      <td>52.521%</td>
      <td>69.702%</td>
      <td>74.784%</td>
      <td>0.702</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2015.html">2015</a>
      </td>
      <td>40</td>
      <td>3</td>
      <td>3</td>
      <td>98</td>
      <td>-1.981%</td>
      <td>72.54%</td>
      <td>25.402%</td>
      <td>126.855%</td>
      <td>0.572</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2014.html">2014</a>
      </td>
      <td>26</td>
      <td>2</td>
      <td>1</td>
      <td>105</td>
      <td>11.664%</td>
      <td>15.221%</td>
      <td>9.182%</td>
      <td>45.428%</td>
      <td>0.335</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2013.html">2013</a>
      </td>
      <td>14</td>
      <td>1</td>
      <td>1</td>
      <td>98</td>
      <td>32.243%</td>
      <td>30.435%</td>
      <td>15.355%</td>
      <td>53.406%</td>
      <td>0.57</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2012.html">2012</a>
      </td>
      <td>29</td>
      <td>5</td>
      <td>5</td>
      <td>94</td>
      <td>13.006%</td>
      <td>16.959%</td>
      <td>25.285%</td>
      <td>63.027%</td>
      <td>0.269</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2011.html">2011</a>
      </td>
      <td>22</td>
      <td>1</td>
      <td>0</td>
      <td>100</td>
      <td>-0.024%</td>
      <td>11.895%</td>
      <td>6.763%</td>
      <td>38.076%</td>
      <td>0.312</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2010.html">2010</a>
      </td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>83</td>
      <td>11.51%</td>
      <td>72.816%</td>
      <td>51.956%</td>
      <td>74.075%</td>
      <td>0.983</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2009.html">2009</a>
      </td>
      <td>214</td>
      <td>0</td>
      <td>0</td>
      <td>64</td>
      <td>25.101%</td>
      <td>131.657%</td>
      <td>130.678%</td>
      <td>87.7%</td>
      <td>1.501</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2008.html">2008</a>
      </td>
      <td>357</td>
      <td>2</td>
      <td>0</td>
      <td>100</td>
      <td>-38.654%</td>
      <td>65.516%</td>
      <td>12.766%</td>
      <td>178.345%</td>
      <td>0.367</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2007.html">2007</a>
      </td>
      <td>17</td>
      <td>1</td>
      <td>0</td>
      <td>97</td>
      <td>2.784%</td>
      <td>135.078%</td>
      <td>15.147%</td>
      <td>373.974%</td>
      <td>0.361</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2006.html">2006</a>
      </td>
      <td>16</td>
      <td>0</td>
      <td>0</td>
      <td>95</td>
      <td>13.478%</td>
      <td>65.414%</td>
      <td>25.448%</td>
      <td>97.949%</td>
      <td>0.668</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2005.html">2005</a>
      </td>
      <td>28</td>
      <td>0</td>
      <td>0</td>
      <td>97</td>
      <td>2.646%</td>
      <td>41.323%</td>
      <td>14.634%</td>
      <td>53.659%</td>
      <td>0.77</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2004.html">2004</a>
      </td>
      <td>20</td>
      <td>0</td>
      <td>0</td>
      <td>132</td>
      <td>8.676%</td>
      <td>12.973%</td>
      <td>2.288%</td>
      <td>19.325%</td>
      <td>0.671</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2003.html">2003</a>
      </td>
      <td>23</td>
      <td>0</td>
      <td>0</td>
      <td>86</td>
      <td>26.469%</td>
      <td>52.899%</td>
      <td>46.833%</td>
      <td>48.317%</td>
      <td>1.095</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2002.html">2002</a>
      </td>
      <td>135</td>
      <td>0</td>
      <td>0</td>
      <td>93</td>
      <td>-24.038%</td>
      <td>63.809%</td>
      <td>30.597%</td>
      <td>78.085%</td>
      <td>0.817</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2001.html">2001</a>
      </td>
      <td>76</td>
      <td>0</td>
      <td>0</td>
      <td>98</td>
      <td>-13.409%</td>
      <td>49.542%</td>
      <td>21.118%</td>
      <td>67.397%</td>
      <td>0.735</td>
    </tr>
  
    
    <tr>
      <td>
        <a href="/files/stock_recs.2000.html">2000</a>
      </td>
      <td>139</td>
      <td>10</td>
      <td>0</td>
      <td>100</td>
      <td>-10.662%</td>
      <td>33.84%</td>
      <td>12.119%</td>
      <td>76.202%</td>
      <td>0.444</td>
    </tr>
  
</table>

</center>

@s When Do We Buy?

What a great question.

We buy when the price drops and we are confident that the price will go back up.

The strategy is to invest a little bit into a lot of stocks, betting that this
"sector" of the market will go up, without placing that guarantee on any
individual stock. As a result, we need to ensure that we have enough
opportunities to invest (since we will likely be investing evenly into each
stock -- I can't predict the future of how many buy signals we'll see over the
course of the year), and we have to balance that with how long we hold each
stock and how much the average ROI is.

#### Price Drop

First off, what does a "drop in price" look like? What kinds of drops are there?
Reviewing the data from the NYSE for 2019 (1 January - 31 December), we get the
following numbers for the fractional 2-day change (from opening of one day to
the close of the next):

--- Price Change and Occurrences
tids  = Ticker.where(:exchange => 'NYSE').all.map {|t| t.id }
debut = Time.parse('1 jan 2019')
fin   = Time.parse('31 dec 2019')
bars  = Bar.where(:date => debut..fin, :ticker_id => tids)
           .order(:ticker_id, Sequel.asc(:date))
           .all
groups  = bars.group_by {|b| b.ticker_id }
changes = groups.map do |ticker_id, bars|
  bars.each_cons(2).map {|a, b| b.change_from a }
end.flatten

# This will sort the changes into the bucket that are closest in value
hist = changes.histogram [-0.35, -0.25, -0.15, -0.05, 0.05, 0.15, 0.25, 0.35]
---

--- Price Change and Occurrences :=
2019
"Fractional 2-day Change" => "# of Occurrences"
               -100..-0.3 => 99
               -0.3..-0.2 => 243
               -0.2..-0.1 => 2532
               -0.1.. 0   => 267752
                0  .. 0.1 => 309317
                0.1.. 0.2 => 3218
                0.2.. 0.3 => 377
                0.3.. 100 => 151
---

Looking at the results for 2015, we get:

--- Price Change and Occurrences :=
2015
"Fractional 2-day Change" => "# of Occurrences"
               -100..-0.3 => 36
               -0.3..-0.2 => 192
               -0.2..-0.1 => 2171
               -0.1.. 0   => 237530
                0  .. 0.1 => 243177
                0.1.. 0.2 => 2490
                0.2.. 0.3 => 238
                0.3.. 100 => 78
---

I therefore decided that -0.2 would be sufficient to start with: we can cull
the herd of opportunities from there.

#### Price Movement

The logic here is based on my theory of price change: the price of a stock
changes when enough sales have occurred to raise the price (an unenlightening
statement), with $\Delta P_{min}$ being the minimum increase in a stock's price:

$$\Delta P_{day} = \Delta P_{min} * N_{shares}$$

Each share that is traded involves a buyer and a seller. The question is whether
the change in price is positive or negative. This is marked by the minimum
change in price.

The minimum increase in a stock's price comes from the idea that you can always
produce a number that is between two others based, so in theory, you could
always undercut someone else's bid that is still higher than the original price.
Since you likely cannot pursue the depths of the Rationals when buying stock,
there is some minimum price ($\Delta P_{min}$) that defines the minimum a stock
price must increase.

With a larger minimum price increase, then fewer sales are required to raise the
price to meet a certain threshold. Dividing both sides by $P_{day - 1}$, we get
the fractional change in price:

$$\frac{\Delta P_{day}}{P_{day - 1}} = \frac{\Delta P_{min} * N_{shares}}{P_{day - 1}}$$

This now represents the fractional ROI. Assuming the $P_{min}$ is constant for
all stocks, $\frac{\Delta P_{min}}{P_{day - 1}}$ will be greater when $P$ is
lower. We want to maximize $N_{shares}$ and minimize $P$, which is summarized in
our maximization of $\frac{N_{shares}}{P_{day - 1}}$, visible in the following
rephrasing:

$$\frac{\Delta P_{day}}{P_{day - 1}} = \Delta P_{min} * \frac{N_{shares}}{P_{day - 1}}$$

The change in price works in both directions, so maximizing the above term
could also lead to a sever price drop. But since we're looking at stocks after
they have already dropped considerably, we're relying on **mean reversion** to
push the price up.

`today.close >= min` sets a minimum price that we're willing to pay; this
(generally, historically) prevents us from investing in stocks that are about
to be delisted (sometimes, not always). It's better to have this than to not.

--- When Do We Buy?
      assessor.buy_when :history => 2 do |history|
        today     = history[-1]
        yesterday = history[-2]
      
        [[today.change_from(yesterday) <= drop,
          today.change_from(today)     <= drop].any?,
  
         today.rank <= rank,
         today.close >= min
        ].all?
      end
---

`today.rank` here is the rank of that ticker at the end of that day. It is
computed through the following lines, and each ticker's daily rank and rank
value are stored in the database within the bar:

--- Computing Rank
# {"SYM" => [Rank, Value]}
rankings = Ticker.rankings NYSE, :date => date
rankings[ticker.symbol] #=> [Rank, Value]
---

@s When Do We Sell?

The goal is not to get the most ROI over an arbitrary amount of time. The goal
is to get the most ROI over a finite period of time, the smaller the better.

This is a work-in-progress: I am balancing individual ROI, because that affects
the hold-time for each stock, because that affects when I have access to the
earnings, because that affects my ability to reinvest that money into this
trading plan.

## Individual ROI

I want to maximize the ROI from each stock that I invest in. This is balanced
with my risk-tolerance.

#### Risk-Tolerance Reduces Over Time

As time goes on, more opportunities to invest will arise, and, being a man with
limited impulse control, I am going to invest in them.

=> This means that as time goes on, I am risking more and more of my money.

=> Since I am risking more and more of my money, I get more and more desperate
to get it back.

=> Since I am getting desperate, I am going to lower my standards for the kinds
of returns that I will accept.

#### What Degree of Polynomial?

The line that marks the threshold above which I will sell a stock could be
anything, so from one perspective, I need to try polynomials of all different
degrees. However, a polynomial would imply that there is a grand, overarching
pattern to the way stocks rise after a drop, which I do not believe to be true,
so I'm just looking to manage my risk appropriately.

<br/>

Anyways, I figured a linear drop ($y = m * x + b$) would be good enough, so I
ran 1,200 tests on the data to find which curve would give me the best results.
It looked roughly like this:

--- Line Fitting
0.00.step(:to => 0.1, :by => 0.005) do |m|
  m = -m
  0.step(:to => 6, :by => 0.1) do |b|
    sim.m = m
    sim.b = b
    sells = sim.assess_sells

    # ...
  end
end
---

The output gave the **results of paper trading those stocks**, based on the idea
that I am going to invest the same amount per investment opportunity (instead of
investing the same amount per year, splitting that amount evenly across an
unknown number of opportunities that will occur during the year).

This raises an interesting point: I am not looking to simply maximize the ROI
over an arbitrary time horizon. Rather, I am trying to maximize my earnings,
which depend on my ability to reinvest my earnings from individual stocks, which
means I want to maximize my ROI but to minimize my hold time, all depending upon
how many buying opportunities present themselves.

## Hold Time

Minimizing the hold time while maximizing the ROI (maximizing $ROI / t_{hold}$)
is tempting, but misleading: the result is that you won't have enough
opportunities to grow your investment, since you end up selling at 10% growth as
soon as you can. It turns out, this is a good strategy, if you have the
opportunities for it.

## Reinvesting Earnings

Reinvesting earnings requires a short hold time (compared to your ultimate time
horizon).

What I have found is that maximizing the ROI while minimizing the hold time
leads me to high-frequency trading (HFT), which presupposes an infinite supply
of trading opportunities. When that supply is limited (e.g., due to trading
fees, commission, etc.), then we end up raising our hold times. I do not yet
have a formula for representing this trade-off.

I've found that with a 20% drop, the defaults of $m = -0.02$ and $b = 5.2$ are
suitable for getting reasonable returns.

--- When Do We Sell?
      # m = -0.02, b = 5.2
      assessor.sell_when do |original, today|
        days_held = today.trading_days_from original
        
        sell_point = [@m * days_held + @b, 0].max
      
        today.change_from(original) >= sell_point
      end
---

@s Metrics of Success

The only real metric of succes is how much "money I've made", but even that is
suspect: is that in reference to the liquid cash I have available at any given
moment, or the total amount of my investments? Can I refine my coefficients ($m$
and $b$) based on only 2018-2020, or as far back as I can? Should I be concerned
that 2013 and 2010 had so few buy signals?

The "reinvested profits" figure comes from investing \$15K into the market that
year. When a buy signal comes along, you invest the value in circulation divided
by 30 into the stock (initially \$15K / 30 = \$500).  When a sell signal comes
along, you sell. You then take the profits and put them back into circulation
(e.g., if you made \$600 profit by selling a stock, your circulation is now
\$15.6K, which means you would now be investing \$520 per stock). The "cash"
figure is the amount of cash you have leftover after all of the buy signals and
all of their sell signals; if a sell signal for a given stock never occurs, then
that investment is still in circulation, but you don't have access to it, which
is reflected in your "cash" value.

Here is the explicit breakdown of the buy and sell signals of 2015, with the
requisite drop being 20% instead (note that some sell signals will occur beyond 2015):

<span onclick="togglediv('togglable')">
  <a>
    Breakdown
    <span id="togglable_plus">[+]</span>
  </a>
</span>
<div id="togglable" style="display: none;">
<pre>
algorithm: VolatileDrop
loaded 40 trxs
	year: 2015
	drop: -0.2
stats: {:m=>-0.02, :b=>5.2} (reinvest: true, pieces: 23.0)
	med. hold:   257
	med. ROI:    0.2880070429723386
	avg. ROI:    1.3103290007605894
	~ ROI/day:   1.0010522195424327
buying AKS	(2015-01-14) for 0.43478260869565216
	cash: 9.565
	circulation: 10.0
buying KBH	(2015-01-15) for 0.43478260869565216
	cash: 9.13
	circulation: 10.0
buying FRO	(2015-01-30) for 0.43478260869565216
	cash: 8.696
	circulation: 10.0
buying AMPY	(2015-02-12) for 0.43478260869565216
	cash: 8.261
	circulation: 10.0
buying AMPY	(2015-03-11) for 0.43478260869565216
	cash: 7.826
	circulation: 10.0
buying AMPY	(2015-03-12) for 0.43478260869565216
	cash: 7.391
	circulation: 10.0
buying MTL	(2015-03-17) for 0.43478260869565216
	cash: 6.957
	circulation: 10.0
buying AMPY	(2015-03-17) for 0.43478260869565216
	cash: 6.522
	circulation: 10.0
buying MTL	(2015-03-18) for 0.43478260869565216
	cash: 6.087
	circulation: 10.0
buying BBD	(2015-03-30) for 0.43478260869565216
	cash: 5.652
	circulation: 10.0
buying EGY	(2015-04-01) for 0.43478260869565216
	cash: 5.217
	circulation: 10.0
buying TWTR	(2015-04-30) for 0.43478260869565216
	cash: 4.783
	circulation: 10.0
buying BTU	(2015-06-15) for 0.43478260869565216
	cash: 4.348
	circulation: 10.0
buying MBI	(2015-06-30) for 0.43478260869565216
	cash: 3.913
	circulation: 10.0
buying FBP	(2015-07-01) for 0.43478260869565216
	cash: 3.478
	circulation: 10.0
buying BTU	(2015-07-02) for 0.43478260869565216
	cash: 3.043
	circulation: 10.0
buying AMPY	(2015-07-02) for 0.43478260869565216
	cash: 2.609
	circulation: 10.0
buying LKM	(2015-07-08) for 0.43478260869565216
	cash: 2.174
	circulation: 10.0
buying LKM	(2015-07-09) for 0.43478260869565216
	cash: 1.739
	circulation: 10.0
buying AMPY	(2015-07-17) for 0.43478260869565216
	cash: 1.304
	circulation: 10.0
buying AMPY	(2015-07-20) for 0.43478260869565216
	cash: 0.87
	circulation: 10.0
buying AMPY	(2015-08-04) for 0.43478260869565216
	cash: 0.435
	circulation: 10.0
selling AMPY	(2015-08-10) at 588.889% (\$0.435 => \$2.995) [15]
	cash: 3.43
	circulation: 12.56
selling AMPY	(2015-08-10) at 365.0% (\$0.435 => \$2.022) [101]
	cash: 5.452
	circulation: 14.147
selling AMPY	(2015-08-10) at 348.193% (\$0.435 => \$1.949) [104]
	cash: 7.4
	circulation: 15.661
selling AMPY	(2015-08-10) at 337.647% (\$0.435 => \$1.903) [105]
	cash: 9.303
	circulation: 17.129
selling AMPY	(2015-08-10) at 490.476% (\$0.435 => \$2.567) [16]
	cash: 11.87
	circulation: 19.262
selling AMPY	(2015-08-28) at 280.909% (\$0.435 => \$1.656) [137]
	cash: 13.527
	circulation: 20.483
selling AMPY	(2015-08-31) at 510.843% (\$0.435 => \$2.656) [41]
	cash: 16.182
	circulation: 22.704
buying BTU	(2015-09-11) for 0.9871374997497189
	cash: 15.195
	circulation: 22.704
buying HMY	(2015-09-22) for 0.9871374997497189
	cash: 14.208
	circulation: 22.704
buying HMY	(2015-09-23) for 0.9871374997497189
	cash: 13.221
	circulation: 22.704
buying SID	(2015-09-24) for 0.9871374997497189
	cash: 12.234
	circulation: 22.704
buying HUN	(2015-09-30) for 0.9871374997497189
	cash: 11.247
	circulation: 22.704
buying P	(2015-10-26) for 0.9871374997497189
	cash: 10.26
	circulation: 22.704
buying CNX	(2015-10-28) for 0.9871374997497189
	cash: 9.272
	circulation: 22.704
buying IO	(2015-11-05) for 0.9871374997497189
	cash: 8.285
	circulation: 22.704
buying FTK	(2015-11-11) for 0.9871374997497189
	cash: 7.298
	circulation: 22.704
buying FTK	(2015-11-12) for 0.9871374997497189
	cash: 6.311
	circulation: 22.704
buying VIPS	(2015-11-16) for 0.9871374997497189
	cash: 5.324
	circulation: 22.704
buying ATV	(2015-12-04) for 0.9871374997497189
	cash: 4.337
	circulation: 22.704
buying CNX	(2015-12-08) for 0.9871374997497189
	cash: 3.35
	circulation: 22.704
buying ATV	(2015-12-08) for 0.9871374997497189
	cash: 2.362
	circulation: 22.704
buying CLF	(2015-12-16) for 0.9871374997497189
	cash: 1.375
	circulation: 22.704
buying TK	(2015-12-18) for 0.9871374997497189
	cash: 0.388
	circulation: 22.704
selling HMY	(2016-02-24) at 326.285% (\$0.987 => \$4.208) [106]
	cash: 4.596
	circulation: 25.925
selling HMY	(2016-02-24) at 334.971% (\$0.987 => \$4.294) [105]
	cash: 8.89
	circulation: 29.232
selling AKS	(2016-03-07) at 0.498% (\$0.435 => \$0.437) [287]
	cash: 9.327
	circulation: 29.234
selling KBH	(2016-03-18) at 1.105% (\$0.435 => \$0.44) [295]
	cash: 9.767
	circulation: 29.239
selling SID	(2016-04-13) at 291.579% (\$0.987 => \$3.865) [138]
	cash: 13.632
	circulation: 32.117
selling BBD	(2016-05-12) at 0.899% (\$0.435 => \$0.439) [283]
	cash: 14.071
	circulation: 32.121
selling CLF	(2016-06-30) at 254.375% (\$0.987 => \$3.498) [135]
	cash: 17.569
	circulation: 34.632
selling MBI	(2016-07-06) at 8.254% (\$0.435 => \$0.471) [256]
	cash: 18.039
	circulation: 34.668
selling LKM	(2016-07-20) at 0.845% (\$0.435 => \$0.438) [261]
	cash: 18.478
	circulation: 34.671
selling CNX	(2016-07-26) at 158.451% (\$0.987 => \$2.551) [186]
	cash: 21.029
	circulation: 36.236
selling CNX	(2016-07-28) at 201.415% (\$0.987 => \$2.975) [160]
	cash: 24.005
	circulation: 38.224
selling HUN	(2016-08-15) at 80.867% (\$0.987 => \$1.785) [220]
	cash: 25.79
	circulation: 39.022
selling LKM	(2016-08-15) at 5.742% (\$0.435 => \$0.46) [278]
	cash: 26.25
	circulation: 39.047
selling FBP	(2016-08-29) at 1.633% (\$0.435 => \$0.442) [293]
	cash: 26.692
	circulation: 39.054
selling MTL	(2016-09-06) at 5.642% (\$0.435 => \$0.459) [372]
	cash: 27.151
	circulation: 39.079
selling MTL	(2016-09-08) at 6.634% (\$0.435 => \$0.464) [373]
	cash: 27.615
	circulation: 39.107
selling ATV	(2016-10-03) at 133.049% (\$0.987 => \$2.301) [206]
	cash: 29.915
	circulation: 40.421
selling FTK	(2016-10-03) at 74.076% (\$0.987 => \$1.718) [224]
	cash: 31.633
	circulation: 41.152
selling ATV	(2016-10-03) at 157.467% (\$0.987 => \$2.542) [208]
	cash: 34.175
	circulation: 42.707
selling FTK	(2016-10-04) at 72.313% (\$0.987 => \$1.701) [224]
	cash: 35.876
	circulation: 43.42
selling AMPY	(2016-10-24) at 432.941% (\$0.435 => \$2.317) [309]
	cash: 38.193
	circulation: 45.303
selling IO	(2016-11-10) at 22.119% (\$0.987 => \$1.205) [256]
	cash: 39.399
	circulation: 45.521
selling P	(2016-12-02) at 5.312% (\$0.987 => \$1.04) [279]
	cash: 40.438
	circulation: 45.573
selling TK	(2016-12-27) at 8.466% (\$0.987 => \$1.071) [257]
	cash: 41.509
	circulation: 45.657
selling VIPS	(2017-03-15) at 0.073% (\$0.987 => \$0.988) [333]
	cash: 42.497
	circulation: 45.658
selling TWTR	(2018-06-05) at 1.324% (\$0.435 => \$0.441) [780]
	cash: 42.937
	circulation: 45.664
selling EGY	(2018-06-12) at 1.224% (\$0.435 => \$0.44) [805]
	cash: 43.377
	circulation: 45.669
selling FRO	(2019-12-19) at 2.999% (\$0.435 => \$0.448) [1231]
	cash: 43.825
	circulation: 45.682
	skips:       2
	profits:     10.0 -> 43.825199048484485
	circulation: 45.681901765625504

</pre>
</div>

<br/>

Below, we have rough summaries for the performance of various sell lines (as
termed by their $m$ and $b$ components) after a 20% drop and a rank of the top
61:

--- Metrics for 2018-2020
"In the cumulative timespan of 2018-2020"

[drop = 20%, m = -0.02, b = 5.2] => ROI: 0.9839851521267415,
                                    Profits: 21.912217326647706,
                                    Hold: 216 days,
                                    Pieces: 50

Yearly Breakdown

| Timeframe |    m  |  b  | Buys | Median Hold | Skips |  Mean ROI  | Reinvested Profits|
|-----------|-------|-----|------|-------------|-------|------------|------------|
|   2018    | -0.02 | 5.2 |   36 |        619  |   0   | -0.14905347|   $8.93 |
|   2019    | -0.02 | 5.2 |   56 |        258  |   4   | 0.322075814|  $14.18 |
|   2020    | -0.02 | 5.2 |  326 |        202  | 235   | 1.222808200|  $28.90 |
---

@s The Algorithm

While the assessor provides the framework for routinely and cleanly assessing
the data, and the simulator pairs the algorithm to the assessor, the contents
of that framework, the actual algorithm, are implemented as subclasses of the
simulator.

--- algos/volatile_drop.rb
module Algorithms
  class VolatileDrop < Simulator
    attr_accessor :m
    attr_accessor :b
    attr_accessor :drop
    attr_accessor :rise # TODO get this out of here

    FOLDER = "volatile_drop"

    # use 23 pieces
    def initialize(stocks:  nil,
                   after:   nil,
                   before:  nil,
                   drop:   -0.2,
                   rank:    60,
                   m:      -0.02,
                   b:       5.2,
                   min:     0.4,
                   **extra)
      super(:stocks => stocks,
            :after  => after,
            :before => before)
      @drop = drop
      @m = m
      @b = b
  
      assessor.buy_when :history => 2 do |history|
        today     = history[-1]
        yesterday = history[-2]
      
        [[today.change_from(yesterday) <= drop,
          today.change_from(today)     <= drop].any?,
  
         today.rank <= rank,
         today.close >= min
        ].all?
      end
      
      # for ROI: m = -0.03, b = 3.0
      # for $$$: m = -0.02, b = 5.2
      #      or: m = -0.00, b = 0.6
      #      (those two average roughly the same from 2008-2020)
      assessor.sell_when do |original, today|
        days_held = today.trading_days_from original
        
        sell_point = [@m * days_held + @b, 0].max
      
        today.change_from(original) >= sell_point
      end
    end
  end
end
---

@s The Simulator

This will be refactored into the assessor, since it's mostly redirection.

--- simulator.rb
require './assessor.rb'

class Simulator
  attr_accessor :assessor
  attr_accessor :stocks
  attr_accessor :after
  attr_accessor :before

  def initialize(stocks:  nil,
                 after:   nil,
                 before:  nil)
    @stocks = stocks
    @after  = after
    @before = before
    @assessor = Assessor.new
  end

  # TODO rebuild all caches in the commented-out format
  def cache_name
    vars = instance_variables - [:@after, :@before, :@stocks, :@assessor]

    #"data/#{self.class::FOLDER}/" +
    #"#{[after.year.to_s, before.year.to_s].uniq.join "-"}_"+ 
    #"#{after.to_i}-#{before.to_i}_" +
    #vars.sort.map {|v| v.to_s[1] + instance_variable_get(v).to_s }.join("_") +
    #".sim"

    "data/#{self.class::FOLDER}/" +
    "#{[after.year.to_s, before.year.to_s].uniq.join "-"}_" +
    vars.map {|v| v.to_s[1] + instance_variable_get(v).to_s }.join("_") +
    ".sim"
  end

  def assess_buys
    @assessor.assess_buys @stocks, :after  => @after,
                                   :before => @before,
                                   :force  => @force
  end

  def assess_sells(partial: false)
    @assessor.assess_sells :partial => partial
  end

  def run
    assess_buys
    assess_sells
  end

  def results
    @assessor.results
  end

  def results=(val)
    @assessor.results = val
  end

  def holding
    @assessor.holding
  end

  def holding=(val)
    @assessor.holding = val
  end

  # Maybe `h[:hold]` should always be filled out?
  # Same with `h[:latest]`?
  def still_negative
    unsold = results.filter {|h| h[:sold] == nil }

    ticks = unsold.map {|h| h[:buy].ticker }
    #latests = Bar.where(:ticker => ticks)
    #             .order(Sequel.desc(:date))
    #             .group(:ticker_id)
    #             .all
    latests = ticks.map do |t|
      [t, Bar.where(:ticker => t)
             .order(Sequel.desc(:date))
             .first]
    end.to_h

    unsold.each do |h|
      h[:latest] = latests[h[:buy].ticker]
      h[:ROI]    = h[:latest].change_from h[:buy]
      h[:hold]   = h[:latest].trading_days_from h[:buy]
    end

    unsold.filter {|h| h[:ROI] < 0 }
  end

  def stats
    statz  = {:date        => after..before,
              :buys        => results.size,
              :unsold      => results.filter {|h| h[:sell].nil? }.size,
              :delisted    => results.filter {|h| h[:delisted] }.size,
              :median_hold => results.map {|h| h[:hold] || 1000 }.median,
              :sp500       => spy(after, before),
              :mean_ROI    => results.map {|h| h[:ROI] }.mean,
              :median_ROI  => results.map {|h| h[:ROI] }.median,
              :stddev_ROI  => results.map {|h| h[:ROI] }.standard_deviation
             }
    statz[:sharpe] = statz[:mean_ROI] / statz[:stddev_ROI]

    statz
  end
end

Dir['./algos/*.rb'].each {|f| require f }

Algorithm = eval("Algorithms::#{CONFIG[:algorithm]}")


---

@s The Assessor



--- assessor.rb
class Assessor
  attr_accessor :buying_plan
  attr_accessor :selling_plan
  attr_accessor :history_requirement

  attr_accessor :holding
  attr_accessor :results

  DELISTING_DEADBAND = 14.days

  def buy_when(history: 2, &b)
    @buying_plan = b
    @history_requirement = history
  end

  def sell_when(&b)
    @selling_plan = b
  end

  def buy?(ticker)
    buying_plan[ticker]
  end

  def sell?(ticker, original)
    selling_plan[ticker, original]
  end

  def assess_buys(tickers, opts={})
    tids = tickers.map {|t| t.id }

    debut  = Time.parse(opts[:after].to_s  || '1 march 1900')
    fin    = Time.parse(opts[:before].to_s || Date.today.to_s)

    bars   = Bar.where(:date => debut..fin, :ticker_id => tids)
                .order(:ticker_id, Sequel.asc(:date))
                .all
    groups = bars.group_by {|b| b.ticker_id }

    @holding = []

    # create groups of size `@history_requirement`, and then
    # pass that history to the checker
    # most recent bar is at -1, oldest bar is at 0
    @holding = groups.map do |ticker_id, bars|
      # assume the history is 
      histories = bars.each_cons history_requirement

      histories.filter do |history|

        # verify that the history is consecutive
        day_deltas = history.each_cons(2).map {|a, b| b.date - a.date }

        if day_deltas.any? {|v| v > 4.days }
          false
        else
          buy? history
        end
      end.map {|history| history.last }
    end.flatten

    # `@holding` currently references the days that a decision to buy is made
    # (using the day's closing price), but we don't *actually* buy until the
    # next morning. So we need to replace these stocks with the next day's
    # stock.
    # 
    # This is key because the `Bar#change_from` method operates on the opening
    # price of the earlier day.
    #
    # If `bars[index + 1]` is nil because we're dealing with some HOT OF THE
    # PRESS stock recommendations, then... I don't really have a plan for that
    # yet.  Then the stock doesn't exist, so just present the stock itself.
    # It'll stay until the time period is recalculated, which happens often.
    #
    # From here on out, we're dealing with *simulation*.
    @holding = @holding.map do |stock|
      bars  = Bar.where(:ticker => stock.ticker,
                        :date => stock.date..(stock.date + 7.days))
                 .order(Sequel.asc(:date))
                 .all
      index = bars.index stock
      bars[index + 1] || stock
    end
  end

  def assess_sells(partial: false)
    # assumes `@holding` and `@results` are accurately mapped
    if partial
      verified = @results.filter {|h| h[:sell] }
      unverified_stocks = @results.filter {|h| h[:sell].nil? }
                                  .map    {|h| h[:buy] }
    else
      unverified_stocks, verified = @holding, []
    end

    # Stocks can be delisted, at which point stocks held will be no longer
    # valid, but then a *new* ticker can start and can *reuse* the old name.
    # And since any stocks held from the previous incarnation won't be valid
    # for the new incarnation of the symbol, we need to separate those
    # instances. We do this by looking for a stretch of 7 days (using the date,
    # not the trading days, since trading days is calculated based on the
    # availability of bar information for that specific stock) during which the
    # stock is not traded (stocks can go intermittently inactive for short
    # periods of time, but that doesn't imply delistment).
    unverified = unverified_stocks.map do |stock|
      bars     = Bar.where(:ticker => stock.ticker) { date >= stock.date }
                    .order(Sequel.asc(:date))
                    .all
      periods = bars.slice_when do |before, after|
        after.date - before.date >= DELISTING_DEADBAND
      end

      # this is the only period that starts from the holding bar
      range = periods.first

      sell_bar = range.find {|day| sell? stock, day }
      delisted = if sell_bar
                   false
                 else 
                   Time.now - range.last.date >= DELISTING_DEADBAND
                 end

      {:buy  => stock,
       :sell => sell_bar,
       :hold => sell_bar ? sell_bar.trading_days_from(stock)  : nil,
       :ROI  => sell_bar ? sell_bar.change_from(stock) : -1,
       :delisted => delisted
      }
    end

    @results = (unverified + verified).sort_by {|h| h[:buy].date }
  end

  def assess(tickers, opts={})
    assess_buys tickers, opts
    assess_sells :partial => opts[:partial]
  end
end

---

@s Accessing Market Data

I use Alpaca.Markets to access market data. At the moment, I only use daily
data. Alpaca's data is unadjusted for splits, and I have found at least one
unresolved issue with their data (January 2018 data for AFL).

--- market.rb
require 'yaml'
Dir.chdir File.dirname(File.expand_path(__FILE__))
CONFIG = YAML.load File.read("config.yml")

require 'open-uri'
require 'alpaca/trade/api'
require 'alphavantagerb'
require './db.rb'
require './simulator.rb'
require 'kder'
require 'histogram/array'

@{Configure the Market APIs}
---

@s Configure the Market APIs

As a matter of boilerplate, I need to link up to the Alpaca API in order to
trade.

--- Configure the Market APIs
Alpaca::Trade::Api.configure do |config|
  config.endpoint   = "https://api.alpaca.markets"
  config.key_id     = CONFIG[:Alpaca][:ID]
  config.key_secret = CONFIG[:Alpaca][:secret]
end

ALP_CLIENT = Alpaca::Trade::Api::Client.new
AV_CLIENT  = Alphavantage::Client.new :key => CONFIG[:AV][:key]

@{Enhance the Alpaca Ruby API}
--- 

@s Enhance the Alpaca Ruby API

Minor issue with the Ruby API: it only allows you to specify the symbols and
limit the number of results returned. The below change allows you to supply
arbitrary options so that the usage of the `CLIENT.bars` can match the web API.

--- Enhance the Alpaca Ruby API
class Alpaca::Trade::Api::Client
  # This takes care of the issue where I was not able to provide other options
  # to the GET request. Now, I can specify "before" and "after" IAW the API.
  def bars(timeframe, symbols, opts={})
    opts[:limit] ||= 100
    opts[:symbols] = symbols.join(',')

    validate_timeframe(timeframe)
    response = get_request(data_endpoint, "v1/bars/#{timeframe}", opts)
    json = JSON.parse(response.body)
    json.keys.each_with_object({}) do |symbol, hash|
      hash[symbol] = json[symbol].map { |bar| Alpaca::Trade::Api::Bar.new(bar) }
    end
  end 

  # Enabling me to use the "qty" query parameter. Playing it extra safe
  # by not even sending the parameter unless there's a specified number
  def close_position(symbol: nil, qty: nil)
    response = delete_request(endpoint,
                              "v2/positions/#{symbol}#{qty ? "?qty=#{qty}" : ""}")
    raise NoPositionForSymbol,
          JSON.parse(response.body)['message'] if response.status == 404

    Position.new(JSON.parse(response.body))
  end
end

@{Market Abstraction}
---

This is what I use to download stock data. No need to stay at the lower levels
of abstraction when all I want to do is download and install the bars.

--- Market Abstraction
module Market
  module Stock
    extend self

    CLOSE = "16:00" # closing time of the markets
    DELAY = 15 * 60 # how long to wait (in sec) before grabbing data

    # Alpaca download but don't install
    def download(tickers, opts={})
      span = opts.delete(:span) || 'day'
      opts[:limit] ||= 1000

      opts.each do |k, v| 
        if [String, Date, DateTime, Time].include? v.class
          opts[k] = DateTime.parse(v.to_s).to_s
        end
      end

      # `CLIENT.bars` returns a hash, so this will also merge them all
      # into one. key collision will only happen if the key is duplicated
      # in the `ticker` argument.
      symbols = tickers.map {|t| t.symbol }
      data    = symbols.each_slice(50).map do |ticks|
        ALP_CLIENT.bars span, ticks, opts
      end.inject({}) {|h, v| h.merge v }

      # strip out any bar that could be from today's incomplete data
      data.each do |sym, bars|
        bars.delete_if do |bar|
          bar.date == Time.parse(Date.today.to_s) &&
          Time.now < (Time.parse(CLOSE) + DELAY)
        end
      end

      # provide a hash so that we can get the ID without
      # fetching the symbol from the DB
      tids = tickers.map {|t| [t.symbol, t] }.to_h

      # Put the data in a hash format so that it's consistent with the
      # AlphaVantage style and allows for easy use with DB#multi_insert
      data.map do |sym, bars|
        [sym, bars.map do |bar|
          {:date   => bar.time,
           :open   => bar.open,
           :high   => bar.high,
           :low    => bar.low,
           :close  => bar.close,
           :volume => bar.volume,
           :span   => 'day',
           :ticker_id => tids[sym].id
          }
        end]
      end.to_h
    end

    def install(tickers, opts={})
      return {} if opts[:after] == Time.parse(Date.today.to_s)
      return {} if opts[:after] == Time.parse(Date.today.to_s) - 1.day &&
                   Time.now < (Time.parse(CLOSE) + DELAY)

      updates = download tickers, opts
      DB[:bars].multi_insert updates.values.flatten

      updates
    end

    # can only do one stock at a time
    # AlphaVantage
    def download_stock(ticker, after: '1900-01-01', before: Date.today.strftime("%Y-%m-%d"))
      stock  = AV_CLIENT.stock :symbol => ticker.symbol
      series = stock.timeseries :outputsize => 'full'

      bars = series.output['Time Series (Daily)']
      bars = bars.filter {|k, bar| k > after && k < before }

      bars.map do |k, bar|
        {:date   => Time.parse(k),
         :open   => bar['1. open'].to_f,
         :high   => bar['2. high'].to_f,
         :low    => bar['3. low'].to_f,
         :close  => bar['4. close'].to_f,
         :volume => bar['5. volume'].to_i,
         :span   => 'day',
         :ticker_id => ticker.id
        }
      end
    end

    def install_stock(stock, **kwargs)
      data = download_stock stock, **kwargs
      DB[:bars].multi_insert data
    end
  end

  module Futures
    def download(future: nil, after: '1900-01-01', before: Date.today.strftime("%Y-%m-%d"))
      url = "https://query1.finance.yahoo.com/v7/finance/download/" +
            "#{future.ymbol}?" +
            "period1=#{after.to_i}&" +
            "period2=#{before.to_i}&" +
            "interval=1d&events=history&includeAdjustedClose=true"
      user_agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) " +
                   "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 " +
                   "Safari/605.1.15"
      data = URI.open(url, "User-Agent" => user_agent) do |site|
        site.read
      end

      data.split("\n").map {|line| line.split "," }.map do |line|
        {:date  => Time.parse(line[0]),
         :open  => line[1].to_f,
         :high  => line[2].to_f,
         :low   => line[3].to_f,
         :close => line[5].to_f,
         :volume => line[6].to_f}
      end
    end
  end
end

---

